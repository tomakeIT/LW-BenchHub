from gr00t.data.dataset import ModalityConfig
from gr00t.data.transform.base import ComposedModalityTransform, ModalityTransform
from gr00t.data.transform.concat import ConcatTransform
from gr00t.data.transform.state_action import (
    StateActionToTensor,
    StateActionTransform,
)
from gr00t.data.transform.video import (
    VideoColorJitter,
    VideoCrop,
    VideoResize,
    VideoToNumpy,
    VideoToTensor,
)
from gr00t.model.transforms import GR00TTransform

from gr00t.experiment.data_config import BaseDataConfig


class X7SDataConfig(BaseDataConfig):
    video_keys = ["video.left_hand_camera", "video.right_hand_camera", "video.eye_in_hand_camera",]
    state_keys = [
        "state.base_x_joint", "state.base_y_joint", "state.base_yaw_link",
        "state.body_z_joint", "state.body_y_joint",
        "state.right_shoulder_y", "state.head_z_joint", "state.left_shoulder_y",
        "state.right_shoulder_x", "state.head_y_joint", "state.left_shoulder_x",
        "state.right_shoulder_z", "state.left_shoulder_z",
        "state.right_elbow_y", "state.left_elbow_y",
        "state.right_elbow_x", "state.left_elbow_x",
        "state.right_wrist_y", "state.left_wrist_y",
        "state.right_wrist_z", "state.left_wrist_z",
        "state.right_gripper1", "state.right_gripper2",
        "state.left_gripper1", "state.left_gripper2"
    ]

    action_keys = [
        "action.base_x_joint", "action.base_y_joint", "action.base_yaw_link",
        "action.body_z_joint", "action.body_y_joint",
        "action.right_shoulder_y", "action.head_z_joint", "action.left_shoulder_y",
        "action.right_shoulder_x", "action.head_y_joint", "action.left_shoulder_x",
        "action.right_shoulder_z", "action.left_shoulder_z", "action.right_elbow_y",
        "action.left_elbow_y", "action.right_elbow_x",
        "action.left_elbow_x", "action.right_wrist_y",
        "action.left_wrist_y", "action.right_wrist_z",
        "action.left_wrist_z", "action.right_gripper1",
        "action.right_gripper2", "action.left_gripper1", "action.left_gripper2"]

    language_keys = ["annotation.human.task_description"]
    observation_indices = [0]
    action_indices = list(range(16))

    def modality_config(self) -> dict[str, ModalityConfig]:
        video_modality = ModalityConfig(
            delta_indices=self.observation_indices,
            modality_keys=self.video_keys,
        )

        state_modality = ModalityConfig(
            delta_indices=self.observation_indices,
            modality_keys=self.state_keys,
        )

        action_modality = ModalityConfig(
            delta_indices=self.action_indices,
            modality_keys=self.action_keys,
        )

        language_modality = ModalityConfig(
            delta_indices=self.observation_indices,
            modality_keys=self.language_keys,
        )

        modality_configs = {
            "video": video_modality,
            "state": state_modality,
            "action": action_modality,
            "language": language_modality,
        }

        return modality_configs

    def transform(self) -> ModalityTransform:
        transforms = [
            # video transforms
            VideoToTensor(apply_to=self.video_keys),
            VideoCrop(apply_to=self.video_keys, scale=0.95),
            VideoResize(apply_to=self.video_keys, height=224, width=224, interpolation="linear"),
            VideoColorJitter(
                apply_to=self.video_keys,
                brightness=0.3,
                contrast=0.4,
                saturation=0.5,
                hue=0.08,
            ),
            VideoToNumpy(apply_to=self.video_keys),
            # state transforms
            StateActionToTensor(apply_to=self.state_keys),
            StateActionTransform(
                apply_to=self.state_keys,
                normalization_modes={key: "min_max" for key in self.state_keys},
            ),
            # action transforms
            StateActionToTensor(apply_to=self.action_keys),
            StateActionTransform(
                apply_to=self.action_keys,
                normalization_modes={key: "min_max" for key in self.action_keys},
            ),
            # concat transforms
            ConcatTransform(
                video_concat_order=self.video_keys,
                state_concat_order=self.state_keys,
                action_concat_order=self.action_keys,
            ),
            # model-specific transform
            GR00TTransform(
                state_horizon=len(self.observation_indices),
                action_horizon=len(self.action_indices),
                max_state_dim=64,
                max_action_dim=32,
            ),
        ]
        return ComposedModalityTransform(transforms=transforms)


class Piper0DataConfig(BaseDataConfig):
    video_keys = ["video.front"]
    state_keys = ["state.single_arm", "state.gripper"]
    action_keys = ["action.single_arm", "action.gripper"]
    language_keys = ["annotation.human.task_description"]
    observation_indices = [0]
    action_indices = list(range(16))

    def transform(self) -> ModalityTransform:
        transforms = [
            # video transforms
            VideoToTensor(apply_to=self.video_keys),
            VideoCrop(apply_to=self.video_keys, scale=0.95),
            VideoResize(apply_to=self.video_keys, height=224, width=224, interpolation="linear"),
            VideoColorJitter(
                apply_to=self.video_keys,
                brightness=0.3,
                contrast=0.4,
                saturation=0.5,
                hue=0.08,
            ),
            VideoToNumpy(apply_to=self.video_keys),
            # state transforms
            StateActionToTensor(apply_to=self.state_keys),
            StateActionTransform(
                apply_to=self.state_keys,
                normalization_modes={key: "min_max" for key in self.state_keys},
            ),
            # action transforms
            StateActionToTensor(apply_to=self.action_keys),
            StateActionTransform(
                apply_to=self.action_keys,
                normalization_modes={key: "min_max" for key in self.action_keys},
            ),
            # concat transforms
            ConcatTransform(
                video_concat_order=self.video_keys,
                state_concat_order=self.state_keys,
                action_concat_order=self.action_keys,
            ),
            # model-specific transform
            GR00TTransform(
                state_horizon=len(self.observation_indices),
                action_horizon=len(self.action_indices),
                max_state_dim=64,
                max_action_dim=32,
            ),
        ]
        return ComposedModalityTransform(transforms=transforms)


LW_DATA_CONFIG_MAP = {
    "x7s": X7SDataConfig(),
    "piper": Piper0DataConfig()
}
